{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Entrenar y evaluar una red neuronal convolucional para resolver un problema de clasificación de imágenes</center>\n",
    "\n",
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Este TP tiene 3 objetivos:</b><br>\n",
    "- Describir conceptos vinculados al entrenamiento y uso de <i>ConvNets</i> para la clasificación de imágenes<br>\n",
    "- Familiarizarse con la librería PyTorch<br>\n",
    "- Reproducir un protocolo para entrenar una red neuronal convolucional y clasificar imágenes.</div>\n",
    "\n",
    "\n",
    "PyTorch es una librería de aprendizaje automático de código abierto para Python, desarrollada principalmente por el grupo de investigación de inteligencia artificial de Facebook. Dentro de PyTorch, el paquete <code>torchvision</code> consiste en conjuntos de datos populares, arquitecturas de modelos y transformaciones de imágenes comunes para la visión artificial.\n",
    "\n",
    "En la primera parte del trabajo práctico, utilizaremos el conjunto de datos CIFAR10 disponible en <code>torchvision</code>.  Este dataset sirve para aprender a resolver un problema de clasificación con 10 clases: 'avión', 'automóvil', 'pájaro', 'gato', 'ciervo', 'perro', 'rana', 'caballo', 'barco', 'camión'. Las imágenes en CIFAR-10 son de tamaño 3x32x32, es decir, imágenes en color de 3 canales de 32x32 píxeles de tamaño: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "El código está basado en el tutorial de PyTorch siguiente: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "<img src=\"cifar10.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver el problema de clasificación de imágenes, seguiremos los siguientes pasos:\n",
    "\n",
    "- Cargar y normalizar los conjuntos de datos de entrenamiento y pruebas utilizando CIFAR10.\n",
    "- Configurar una red neuronal de convolución\n",
    "- Definir una función de pérdida\n",
    "- Optimizar la red sobre los datos de entrenamiento\n",
    "- Probar el rendimiento de la red con los datos de test\n",
    "\n",
    "Por cada paso, se solicita responder a una serie de preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y normalizar el dataset CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "#We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "1) ¿Cuál es el tamaño del dataset de entrenamiento y del dataset de test? (Imprimir el resultado con la función <code>print</code>)<br>\n",
    "2) ¿Por qué el parametro <code>shuffle</code> se configura \"True\" para el dataset de entrenamiento y \"False\" para el dataset de test? ¿De qué sirve este parametro?<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#45b39d \">Sus respuestas...</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 50000 \n",
      "test: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",len(trainset),\"\\ntest:\",len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R:</b>shuffle se define verdadero para revolver la data en cada época,lo que significa que en cada iteración se toman datos distintos, ya que para el dataset de prueba es necesario tener datos fijos se define como FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código siguiente permite mostrar imagenes aleatorias del dataset de entrenamiento y su etiqueta real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane  ship   cat  frog\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def imagesFromBatches(iterator,quantity):\n",
    "    dataiter = iter(iterator)\n",
    "    images, labels = dataiter.next()    \n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(quantity)))\n",
    "    return (images,labels)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net1 = Net()\n",
    "\n",
    "summary(net1,(3,32,32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "1) ¿Cuántas capas tiene esta ConvNet?<br><b>7 capas</b><br>\n",
    "2) Explicar los parametros de cada capa. ¿Cuántos filtros se utilizan en las capas de convolución? ¿Cuál es el tamaño de los filtros? <br><b>6 filtros de 5x5 en la primera convolucion y 16 de 5x5 en la segunda convolucion </b><br>\n",
    "3) ¿Cuál es la diferencia entre la función <code>init</code> y <code>forward</code>?<br><b>init define las instrucciones mientras que forward las ejecuta y enlaza, define cual instuccion sigue a cual</b><br>\n",
    "4) ¿De qué sirve la función view()? Explicar sus parametros.<br><b>\"aplana\" la imagen convirtiendo las multiples capas a vectores</b><br>\n",
    "5) ¿Cuántos paramétros en total se tiene que aprender con esta ConvNet? <br><b>62006 parametros</b><br>\n",
    "6) ¿Por qué se utiliza la función <code>conv2d</code> aunque tenemos imagenes con 3 canales?<b>por que estamos trabajando con obetos 2d(información bimensional), los 3 canales son para interpretar la información 2d</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.530\n",
      "[1,  4000] loss: 1.481\n",
      "[1,  6000] loss: 1.451\n",
      "[1,  8000] loss: 1.387\n",
      "[1, 10000] loss: 1.356\n",
      "[1, 12000] loss: 1.360\n",
      "[2,  2000] loss: 1.283\n",
      "[2,  4000] loss: 1.259\n",
      "[2,  6000] loss: 1.251\n",
      "[2,  8000] loss: 1.234\n",
      "[2, 10000] loss: 1.231\n",
      "[2, 12000] loss: 1.214\n",
      "[3,  2000] loss: 1.151\n",
      "[3,  4000] loss: 1.147\n",
      "[3,  6000] loss: 1.169\n",
      "[3,  8000] loss: 1.143\n",
      "[3, 10000] loss: 1.144\n",
      "[3, 12000] loss: 1.130\n",
      "[4,  2000] loss: 1.039\n",
      "[4,  4000] loss: 1.088\n",
      "[4,  6000] loss: 1.075\n",
      "[4,  8000] loss: 1.085\n",
      "[4, 10000] loss: 1.092\n",
      "[4, 12000] loss: 1.083\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ver la video: https://www.youtube.com/watch?v=ErfnhcEV1O8 - A Short Introduction to Entropy, Cross-Entropy and KL-Divergence\n",
    "\n",
    "- Leer: http://ruder.io/optimizing-gradient-descent/index.html - An overview of gradient descent optimization algorithm\n",
    "\n",
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "1) ¿Qué hace la función <code>CrossEntropyLoss</code>? Qué devuelve? Con qué otra función se podría reemplazar <code>CrossEntropy</code>?<br><b>genera un criterion que calcula la Perdida de Entropia Cruzada. retorna un valor entre 0 y 'C'-1, indicando que tan errada esta la predicción (menor es mejor).\n",
    "    Se podria reemplazar por una combinacion de nn.LogSoftmax y nn.NLLLoss</b><br>\n",
    "2) ¿Cuál es la diferencia principal entre los métodos de optimización Gradient Descent, Stochastic Gradient Descent y Mini-Batch Gradient Descent?<br><b>Gradient Descent is an iterative method to solve the optimization problem. There is no concept of \"epoch\" or \"batch\" in classical gradient decent. The key of gradient decent are\n",
    "    -Update the weights by the gradient direction.<br>\n",
    "    -The gradient is calculated precisely from all the data points.<br>\n",
    "Stochastic Gradient Descent can be explained as: quick and dirty way to \"approximate gradient\" from one single data point. If we relax on this \"one single data point\" to \"a subset of data\", then the concepts of batch and epoch come.<br>mini-batch gradient has a little bit noisy cost function but still trend downwards. The reason for the noise is that there are some harder mini batches which cause oscillation to cost function.\n",
    "</b><br>\n",
    "3) ¿En nuestro ejemplo, qué método utilizamos? En qué parte del código se podría cambiar el tamaño del batch?<br><b>usamos SGD, en la definicion de los sets(al comienzo del notebook)</b><br>\n",
    "4) ¿Qué metafora podemos utilizar para entender la idea del parametro <code>momentum</code>?<br><b></b><br>\n",
    "5) ¿Podría ser útil aumentar el número de epoch? ¿Por qué? De qué sirve este parametro?<br><b>Es útil aumentar el número de epoch si la función de pérdida es muy elevada, por contraparte, si se aumentan las epoch en exceso, es muy probable que se llegue a un valor no aconsejable, que se aleje del óptimo en vez de acercarse.El número de Epoch sirve para iterar sobre las iteraciones de SGD en este caso</b><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar la CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos 4 ejemplos del dataset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "BatchSize=4\n",
    "\n",
    "images,labels= imagesFromBatches(testloader,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificamos estas 4 imágenes con nuestra CNN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship plane plane\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(BatchSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  ship  ship plane\n",
      "Accuracy of the network on the 4 test images: 75 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        images, labels = imagesFromBatches(testloader,BatchSize)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (BatchSize,\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Pregunta</b><br>\n",
    "1) ¿Cuál es el rendimiento del modelo entrenado sobre estos primeros ejemplos?<br><b>Revisar celda anterior</b><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "Calculamos el rendimiento de nuestra CNN sobre todos los datos del training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos el rendimiento de la CNN calculando su exactitud según cada etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 67 %\n",
      "Accuracy of   car : 73 %\n",
      "Accuracy of  bird : 46 %\n",
      "Accuracy of   cat : 40 %\n",
      "Accuracy of  deer : 61 %\n",
      "Accuracy of   dog : 51 %\n",
      "Accuracy of  frog : 80 %\n",
      "Accuracy of horse : 42 %\n",
      "Accuracy of  ship : 69 %\n",
      "Accuracy of truck : 65 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas:</b><br>\n",
    "1) ¿Qué paramétros podrían modificar para tratar de mejorar el rendimiento de la CNN? <br><b>Se pueden modificar tanto el BatchSize como el numero de Epoch, Learning Rate, Capas de convolucion, de pool, modificar los filtros, Tambien es posible cambiar la Arquitectura</b><br>\n",
    "2) ¿Cómo se llama la arquitectura de CNN que hemos utilizado? (ver slides del curso y https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5 y https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)<br><b>LeNet-5</b><br>\n",
    "3) ¿Qué pasa si tratan de agregar más filtros en la segunda capa de convolución? <br><b>aumentan/disminuyen los parametros si es que se incrementan/decrementan los filtros</b><br>\n",
    "4) ¿Qué pasa si trata de agregar una tercera capa de convolución y pooling? <br><b>LeNet-5 esta definido de la forma ya planteada, si se agregase otra capa de convolucion y pooling, el código no funcionaría, como se ve en la celda de abajo</b><br>\n",
    "5) ¿En la literatura, qué arquitecturas CNN permiten obtener mejores rendimiento que la arquitectura LeNet-5? Cuál es el limite de estas arquitecturas? <br><b></b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 400]' is invalid for input of size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-095eb829d3af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mnet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-095eb829d3af>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 400]' is invalid for input of size 64"
     ]
    }
   ],
   "source": [
    "summary(net1,(3,32,32))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net2 = Net()\n",
    "\n",
    "summary(net2,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>T.P</b><br>\n",
    "Optimizar una CNN para resolver el problema asociado al dataset Fashion-MNIST (https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist). <br>\n",
    "\n",
    "1) ¿La arquitectura LeNet-5 es mejor que Random Forest? Comparar el rendimiento obtenido con lo obtenido por el algoritmo RandomForest (con 50 estimadores).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trainSet=torchvision.datasets.FashionMNIST(\"FashionMNIST\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "testSet=torchvision.datasets.FashionMNIST(\"FashionMNIST\", train=False, transform=transforms.ToTensor(), target_transform=None, download=False)\n",
    "\n",
    "# https://github.com/AbhirajHinge/CNN-with-Fashion-MNIST-dataset/blob/master/FashionMNISTwithCNN.py\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=trainSet,batch_size=batch_size,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=testSet,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             416\n",
      "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
      "              ReLU-3           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 16, 14, 14]               0\n",
      "            Conv2d-5           [-1, 32, 14, 14]          12,832\n",
      "       BatchNorm2d-6           [-1, 32, 14, 14]              64\n",
      "              ReLU-7           [-1, 32, 14, 14]               0\n",
      "         MaxPool2d-8             [-1, 32, 7, 7]               0\n",
      "            Linear-9                   [-1, 10]          15,690\n",
      "================================================================\n",
      "Total params: 29,034\n",
      "Trainable params: 29,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.47\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "cnn=CNN()\n",
    "summary(cnn,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5, Iter : 100/600,  Loss: 0.3133\n",
      "Epoch : 1/5, Iter : 200/600,  Loss: 0.3850\n",
      "Epoch : 1/5, Iter : 300/600,  Loss: 0.2938\n",
      "Epoch : 1/5, Iter : 400/600,  Loss: 0.3733\n",
      "Epoch : 1/5, Iter : 500/600,  Loss: 0.3865\n",
      "Epoch : 1/5, Iter : 600/600,  Loss: 0.4329\n",
      "Epoch : 2/5, Iter : 100/600,  Loss: 0.3191\n",
      "Epoch : 2/5, Iter : 200/600,  Loss: 0.2917\n",
      "Epoch : 2/5, Iter : 300/600,  Loss: 0.3010\n",
      "Epoch : 2/5, Iter : 400/600,  Loss: 0.1556\n",
      "Epoch : 2/5, Iter : 500/600,  Loss: 0.3015\n",
      "Epoch : 2/5, Iter : 600/600,  Loss: 0.2419\n",
      "Epoch : 3/5, Iter : 100/600,  Loss: 0.3474\n",
      "Epoch : 3/5, Iter : 200/600,  Loss: 0.2880\n",
      "Epoch : 3/5, Iter : 300/600,  Loss: 0.2552\n",
      "Epoch : 3/5, Iter : 400/600,  Loss: 0.2694\n",
      "Epoch : 3/5, Iter : 500/600,  Loss: 0.2399\n",
      "Epoch : 3/5, Iter : 600/600,  Loss: 0.3299\n",
      "Epoch : 4/5, Iter : 100/600,  Loss: 0.1957\n",
      "Epoch : 4/5, Iter : 200/600,  Loss: 0.1793\n",
      "Epoch : 4/5, Iter : 300/600,  Loss: 0.3432\n",
      "Epoch : 4/5, Iter : 400/600,  Loss: 0.2117\n",
      "Epoch : 4/5, Iter : 500/600,  Loss: 0.3102\n",
      "Epoch : 4/5, Iter : 600/600,  Loss: 0.2122\n",
      "Epoch : 5/5, Iter : 100/600,  Loss: 0.2505\n",
      "Epoch : 5/5, Iter : 200/600,  Loss: 0.2104\n",
      "Epoch : 5/5, Iter : 300/600,  Loss: 0.3387\n",
      "Epoch : 5/5, Iter : 400/600,  Loss: 0.2472\n",
      "Epoch : 5/5, Iter : 500/600,  Loss: 0.2569\n",
      "Epoch : 5/5, Iter : 600/600,  Loss: 0.2046\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5;\n",
    "batch_size = 100;\n",
    "learning_rate = 0.001;\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);\n",
    "\n",
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(loss.data.numpy())\n",
    "        losses.append(loss.data.numpy());\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "learning_rate=0.015\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "iter=0\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate (train_loader):\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images,labels in test_loader:\n",
    "                images=Variable(images)\n",
    "\n",
    "                outputs=model(images)\n",
    "                \n",
    "                _,predicted=torch.max(outputs.data,1)\n",
    "                total+=labels.size(0)\n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy= (100.0* correct)/(total)\n",
    "            print(\"Iteration:\"+str(iter)+\"  Loss:\"+str(loss)+\"  Accuracy:\"+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:197: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:204: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:500  Loss:tensor(0.5544, grad_fn=<NllLossBackward>)  Accuracy:tensor(76)\n",
      "Iteration:1000  Loss:tensor(0.5597, grad_fn=<NllLossBackward>)  Accuracy:tensor(79)\n",
      "Iteration:1500  Loss:tensor(0.3586, grad_fn=<NllLossBackward>)  Accuracy:tensor(82)\n",
      "Iteration:2000  Loss:tensor(0.4738, grad_fn=<NllLossBackward>)  Accuracy:tensor(82)\n",
      "Iteration:2500  Loss:tensor(0.4469, grad_fn=<NllLossBackward>)  Accuracy:tensor(84)\n",
      "Iteration:3000  Loss:tensor(0.2858, grad_fn=<NllLossBackward>)  Accuracy:tensor(85)\n",
      "Iteration:3500  Loss:tensor(0.4493, grad_fn=<NllLossBackward>)  Accuracy:tensor(85)\n",
      "Iteration:4000  Loss:tensor(0.4104, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:4500  Loss:tensor(0.2744, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:5000  Loss:tensor(0.4505, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:5500  Loss:tensor(0.3778, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:6000  Loss:tensor(0.2715, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:6500  Loss:tensor(0.3987, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:7000  Loss:tensor(0.4063, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:7500  Loss:tensor(0.4968, grad_fn=<NllLossBackward>)  Accuracy:tensor(86)\n",
      "Iteration:8000  Loss:tensor(0.1797, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:8500  Loss:tensor(0.3062, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:9000  Loss:tensor(0.2335, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:9500  Loss:tensor(0.3177, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:10000  Loss:tensor(0.3549, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:10500  Loss:tensor(0.2129, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:11000  Loss:tensor(0.3989, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:11500  Loss:tensor(0.1961, grad_fn=<NllLossBackward>)  Accuracy:tensor(87)\n",
      "Iteration:12000  Loss:tensor(0.3625, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:12500  Loss:tensor(0.2944, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:13000  Loss:tensor(0.1716, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:13500  Loss:tensor(0.2687, grad_fn=<NllLossBackward>)  Accuracy:tensor(88)\n",
      "Iteration:14000  Loss:tensor(0.3505, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:14500  Loss:tensor(0.3283, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:15000  Loss:tensor(0.2834, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:15500  Loss:tensor(0.2631, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:16000  Loss:tensor(0.2826, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:16500  Loss:tensor(0.2517, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:17000  Loss:tensor(0.2503, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:17500  Loss:tensor(0.1661, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n",
      "Iteration:18000  Loss:tensor(0.2135, grad_fn=<NllLossBackward>)  Accuracy:tensor(89)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import torch\n",
    "import codecs\n",
    "\n",
    "\n",
    "class fashion(data.Dataset):\n",
    "    \n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(os.path.join(root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "\n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def parse_byte(b):\n",
    "    if isinstance(b, str):\n",
    "        return ord(b)\n",
    "    return b\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        labels = [parse_byte(b) for b in data[8:]]\n",
    "        assert len(labels) == length\n",
    "        return torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        images = []\n",
    "        idx = 16\n",
    "        for l in range(length):\n",
    "            img = []\n",
    "            images.append(img)\n",
    "            for r in range(num_rows):\n",
    "                row = []\n",
    "                img.append(row)\n",
    "                for c in range(num_cols):\n",
    "                    row.append(parse_byte(data[idx]))\n",
    "                    idx += 1\n",
    "        assert len(images) == length\n",
    "        return torch.ByteTensor(images).view(-1, 28, 28)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "train_dataset=fashion(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=fashion(root='./data',train=False,transform=transforms.ToTensor(),download=True)\n",
    "batch_size=100\n",
    "n_iters=18000\n",
    "num_epochs=n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs=int(num_epochs)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (CNNModule,self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
    "        self.relu1=nn.ELU()\n",
    "        nn.init.xavier_uniform(self.cnn1.weight)\n",
    "\n",
    "\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.cnn2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "        self.relu2=nn.ELU()\n",
    "        nn.init.xavier_uniform(self.cnn2.weight)\n",
    "\n",
    "\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.fcl=nn.Linear(32*7*7,10)\n",
    "    def forward(self,x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        #print (\"CNN1\")\n",
    "        #print (out.size())\n",
    "        \n",
    "        out=self.maxpool1(out)\n",
    "        #print (\"Maxpool1\")\n",
    "        #print (out.size())\n",
    "        \n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        #print (\"CNN2\")\n",
    "        #print (out.size())\n",
    "        out=self.maxpool2(out)\n",
    "        #print (\"Maxpool2\")\n",
    "        #print (out.size(0))\n",
    "        \n",
    "        out=out.view(out.size(0),-1)\n",
    "\n",
    "        out=self.fcl(out)\n",
    "\n",
    "        return out\n",
    "model=CNNModule()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "learning_rate=0.015\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "iter=0\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate (train_loader):\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images,labels in test_loader:\n",
    "                images=Variable(images)\n",
    "\n",
    "                outputs=model(images)\n",
    "                \n",
    "                _,predicted=torch.max(outputs.data,1)\n",
    "                total+=labels.size(0)\n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy= (100.0* correct)/(total)\n",
    "            print(\"Iteration:\"+str(iter)+\"  Loss:\"+str(loss)+\"  Accuracy:\"+str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
